---
author: "Min-Jung Jung"  
date: "10/29/2021"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, eval = FALSE}
rmarkdown:: render("_Rmd/2021-10-30-Automation-Blog-Post.Rmd",
                   output_format = "github_document",
                   output_dir = "../mjung5.github.io/_posts", 
                   output_options = list(html_preview = FALSE, keep_html = FALSE)
                   )
```

The [project 2](https://mjung5.github.io/online-news-prediction/) [(github repo)](https://github.com/mjung5/online-news-prediction) was a group project working with a partner to create models to predict the number of shares of articles published in Mashable in a period of two years and to automate Markdown reports using 6 different channel variables. 

Beginning with manipulating data, we performed Exploratory Data Analysis on several interesting variables, like number of images and videos and created various graphs and summary statistics. Next, we fit two linear regression models and two ensemble tree-based models(a random forest models and a boosted tree model) and then we compared the RMSE scores of each model fit and found the best model with the lowest RMSE score.

what would you do differently?

Deciding on the variables for the EDA was very challenging because many variables were unknown. Therefore, I and David decided on starting EDA with the variables that are familiar, then adding more later. As we read more articles using [Online News Popularity Data set](https://archive.ics.uci.edu/ml/datasets/online+news+popularity), we learned more about some variables, like positive and negative polarity, and added those variables into our EDA. End up, we had to change the codes so many times. In the future, I would pick a set of variables and stick with the variables for the EDA to save time. 

what was the most difficult part for you?

I fit the random forest model and I struggled so much running the code chunk because of the running time. It took me almost 2-3 hours to render. However, I found out that it was not only my struggle, and I was able to get some suggestions and advice through the discussion board, the office hour, and the slack channel. Eventually, I was able to use chunk option catch=TRUE, and was able to reduce time after rendering the first time. 

what are your big take-aways from this project?

I am so glad I was about to learn how to set up automation and producing automated markdown reports. Thankfully, David helped me a lot on understanding the process of setting up the automation and we shared lots of ideas. I am so excited about using this method for different data analysis. Also, working with partner using github was surprisingly pleasant. We communicated more to avoid merge conflict and saved more time not dealing with emailing back and forth with revised files.   
